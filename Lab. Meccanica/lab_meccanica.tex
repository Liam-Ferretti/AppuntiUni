\documentclass[a4paper,12pt, openany]{book}

% pacchetti comuni
\input{../preambolo.tex}

% info documento
\title{Appunti di Laboratorio di Meccanica}
\author{Liam Ferretti}
\date{\today}

\begin{document}
	
	\maketitle
	\tableofcontents
	\clearpage
	
	\chapter{Probabilità}
	Per probabilità si intende un numero: $0 \leq p \leq 1$.
	
	La valutazione di P:
	\begin{itemize}
		\item Combinatoria: non si addice a tutti i casi, nello specifico in quelli scientifici utili a definire la natura:
		\subitem\[\{e_i\} \text{ evento elementare} \Rightarrow \text{ se } \{e_i\} \text{ si verifica } \Rightarrow\ \text{ successo}\]
		E, A, B, eventi compositi
		l'evento complementare di E è $\overline{E}$, ovvero non si verifica E, sono mutualmente esclusivi, se si verifica E, non si può verificare $\overline{E}$
	\end{itemize}
	\section{Condizione di Laplace:}
	
	La probabilità di ogni evento è uguale a un certo numero p per ogni i:
	\[P(\{e_i\}) = p \forall i\]
	
	Presi allora n casi possibili, quindi n eventi elementari, allora:
	\[p = \frac{1}{n} \Rightarrow P(\{e_i\}) = \frac{1}{n}\]
	
	Definito un certo evento compositi, $E_j$, con $n_j$ eventi favorevoli allora:
	\[P(E_j) = n_j \frac{1}{n}\]
	Def di Laplace (combinatori) di P:
	\[P(E) = \frac{\text{numero di casi favorevoli}}{\text{numero di casi totali ed equiprobabili}}\]
	Questa definizione non è universale, in quanto non sapendo i casi totali o favorevoli non è valida.
	
	\section{Valutazione frequentista, legge empirica del caso}
	Prese n misure, ed una carta modalità $\{e_i\}$ (per un dato una delle facce).
	\[p(E_i) = \frac{n(E_i)}{n} \Rightarrow p \approx \frac{\text{successi}}{\text{prove totali}}\]
	non è giusto dire:
	\[p = \lim_{n \rightarrow +\infty} \frac{\text{successi}}{\text{prove}} = \frac{n_j}{n}\]
	
	\section{Probabilità composta/condizionata}
	Preso E un certo evento, allora:
	\[E \mid I\]
	dove I è lo stato di informazione, e si legge E condizionato I, allora:
	\[P(E \mid I) = P(E)\]
	ovvero la probabilità di E condizionato I, e la condizione I è sempre implicita, preso un altro evento C, se si vuole calcolare la probabilità di:
	\[P(E \mid C)\]
	bisogna calcolare la probabilità che si verifichi C e poi quella in cui si verifica E, ed equivale a:
	\[P(E \mid C) = \frac{\text{casi favorevoli a E ed a C}}{\text{casi favorevoli a C}}\]
	In generale se C non si verifica non posso definire la probabilità, e quindi anche se non ho uno stato di informazione non la posso definire.
	
	Ad esempio se P è la probabilità che un certo cavallo vinca una certa gara se la gara si svolge, ma piove e quindi la gara non si svolge e quindi non essendosi svolta la gara non è possibile definire la probabilità di vincita, e quindi non si può dire che sia nulla.
	
	\section{Definizione di probabilità}
	È una definizione soggettiva di P, deve essere una rational bet, e si ottiene un grado di fiducia.
	
	Presa A una certa puntata e E un certo evento, allora 
	\[A \alpha P(E)\]quindi più è alta la puntata più è alta la probabilità, definendo S un certo premio, allora \[A \alpha S\]
	\[A \alpha P(E)S\]
	Invece $\overline{E} \rightarrow P(\overline{E})$, e B e la puntata su $\overline{E}$, quindi:
	\[P(E) = \frac{A}{S}\]
	se $S = 1$, allora:
	\[P(E) = A\]
	quindi avendo che $A \leq S \Rightarrow 0 \leq P(E) \leq 1$
	
	Invece:
	\[B = P(E)S\]
	Quindi:
	\[A + B = S (P(E) + P(\overline{E}))\]
	\[P(E) + P(\overline{E}) = 1\]
	\[P(E\mid I) + P(\overline{E}\mid I) = 1\]
	ovvero l'assioma della probabilità.
	
	\[\frac{A}{B} = \frac{P(E)}{P(\overline{E})}\]
	\[\Rightarrow P(E) = \frac{A}{B}P(\overline{E}) = \frac{A}{B}\frac{B}{A} = \frac{A}{S} = \frac{A}{A + B}\]
	Presi ad esempio $A = 2, B=1$, allora:
	\[P(E) = \frac{2}{3}, P(\overline{E}) = \frac{1}{3}\]
	Si dice di probabilità di un evento E, il grado di fiducia ..., bisogna però assumere che il risutalto delle misura è soggettivo, dipende dallo stato di informazione, ma deve essere comunque ragionevole, quindi l'osservatore è parte fondamentale del processo di misura anche nel mondo deterministico.
	
	\section{Assiomi delle probabilità}
	\begin{itemize}
		\item Un evento certo è definito con $\Omega$, ha probabilità 1
		\item Un evento impossibile, ha probabilità 0
		\item Probabilità di implicazione:
		\[E_1 \subseteq E_2\]
		Se si verifica $E_1$ si deve verificare anche $E_2$
		\item Evento opposto, $\overline{E}$ opposto di E, se E è vero allora $\overline{E}$ è falso e vice verso.
		\item Prodotto logico (AND): 
		\[E_1 \cap E_2\]
		\[\Rightarrow E \cap \overline{E} = \emptyset\]
		\[(E_1 \cap E_2) \subseteq E_2 \wedge \subseteq E_1\]
		definito sovrapposizione o overlap.
		\item Somma logica:
		\[E_1 \cup E_2\] vera se si verifica $E_1$ oppure $E_2$
		\subitem La somma logica tra $E$ e $\overline{E}$, ovvero \[E \cup \overline{E} = \Omega\]
		\[E_2, E_1 \subseteq (E_1 \cup E_2\]
		\item Classe completa di eventi:
		\[\bigcup_{i = 1} ^n E_i = \Omega\]
		\[E_i \cap E_j = \emptyset, \forall i \not = j\]
		quindi sono eventi mutualmente esclusivi.
		
		Presi $E_1 \cap E_2 = \emptyset$, allora:
		\[P(E_1 \cup E_2) = P(E_1) + P(E_2)\]
		\[P(E \cup \overline{E}) = P(E) + P(\overline{E}) = P(\Omega) = 1\]
		\[P(\bigcup_{i = 1}^n E_1) = P(\Omega) = 1\] 
		
		Se i due eventi non sono disgiunti allora:
		\[P(E_1 \cup E_2) = P(E_1) + P(E_2) - P(E_1 \cap E_2)\]
		Presi due insiemi A, B, allora:
		\[P(A \cup B) \leq P(A) + P(B)\]
		Posso definire l'unione tra A e B:
		\[A \cup B = (A \cap \overline{B}) \cup (A \cap B) \cup (B \cap \overline{A})\]
		\[A = (A \cap \overline{B}) \cup (A \cap B)\]
		\[B = (B \cap \overline{A}) \cup (B \cap A)\]
		Sottraendo e calcolando le probabilità si ottiene che:
		\[P(A \cup B) - P(A) - P(B) = P(A \cap \overline{B}) + P(A \cap B) + P(B \cap \overline{A}) - P(A \cap B) + \]\[- P(A \cap \overline{B}) - P(B \cap A) - P(B \cap \overline{A})\]
		\[\Rightarrow P(A \cup B) = P(A) + P(B) - P(A \cap B)\]
	\end{itemize}
	
	\section{Probabilità condizionata 2}
	Perso H il condizionante, E l'evento, e $\Omega$ l'evento completo, allora:
	\[P(E | H), se H \in \Omega, H \Rightarrow \Omega, P(H) \not = 0\]
	Bisogna comparare quindi:
	\[P(E|H)\]
	e:
	\[P(E \wedge H)\]
	e sappiamo che:
	\[P(E|H) \geq P(E \wedge H)\]
	inoltre:
	\[P(E|H) = P(E \wedge H) \iff H = 1\]
	In generale:
	\[P(E|H) \not = P(H | E)\]
	ed inoltre: $P(E \wedge H) = P(H \wedge E)$, solo se a proprietà non è condizionata.
	
	\subsection{Legge della proprietà composta}
	È un teorema se visto con il paradigma della rational bet.
	\[P(E | H) \cdot P(H) = P(E \wedge H) \Rightarrow P(E|H) = \frac{P(E \wedge H)}{P(H)}\]
	$E | H$ non è definito se $H$ non è verificata.
	
	Sapendo che:
	\[P(E \wedge H) = P(H \wedge E)\]
	allora:
	\[P(E | H)P(H) = P(H | E)P(E) \Rightarrow \frac{P(E | H)}{P(E)} = \frac{P(H | E)}{P(H)}\]
	Interpretandolo con l'interpretazione frequentista, equivarrebbe a:
	\[P(E|H) = \frac{P(E \wedge H)}{P(H)} = \frac{\text{num casi favorevoli ad E e H}}{\text{num casi favorevoli ad H}}\]
	
	\section{Teorema della probabilità composta}
	\[P(E|H) = \frac{P(E \wedge H)}{P(H)} = \frac{A}{S}\]
	dove A è la quantità che si scommette, ed S è la vincita, se S è uguale a 1, allora:
	\[P(E|H) = A, A \in [0, 1]\]
	La previsione del guadagno, $\phi$, deve essere nullo, per il fatto che la scommessa deve essere una rational bet.
	\[\phi = -A + SP(E \wedge H) + AP(\overline{H})\]
	dove $-A$ equivale alla puntata iniziale, $SP(E \wedge H)$ la probabilità di vincere S, $AP(\overline{H}$ la probabilità del ritorno della puntata quando H non si verifica.
	\[\phi = G = -P(E | H) + P(E \wedge H) + P(E | H)(1 - P(H))\]
	\[P(E \wedge H) = P(E | H)P(H) = P(E | H ) = \frac{P(E \wedge H)}{P(H)}\]
	
	\subsection{Eventi indipendenti (in probabilità)}
	Se:
	\[P(E | H) = P(E)\]
	vuol dire che i due aventi hanno probabilità indipendenti.
	\[P(E \cap H) = P(E | H)P(H) = P(E)P(H)\]
	ovvero la legge dei moltiplicazione delle probabilità, solo se i due eventi sono indipendenti in probabilità, se non lo sono, allora l'ultimo passaggio non è valido.
	Se si hanno più condizionanti, allora, se tutti gli $E_i$ sono indipendenti in probabilità, allora:
	\[P(E_1 \cap E_2 \cap \cdots \cap E_n) = \prod_{i = 1}^{n}P(E_i)\]
	
	\section{Legge delle alternative (disintegrazione delle probabilità)}
	Classe completa di ipotesi, $H_i, i \in \{1, \cdots, n\}$
	\[\begin{cases} \displaystyle
		\bigcup_{i = 1}^{n} H_i = \Omega \\
		H_i \cap H_j = \emptyset \forall i \not= j
	\end{cases}\]
	Preso un certo evento E che implica Omega, allora:
	\[E = \bigcup_{i = 1}^{n}(E \cap H_i)\]
	in probabilità:
	\[P(E) = \sum_{i = 1}^{n} P(E \cap H_i) \Rightarrow P(E) = \frac{\sum_{i = 1}^{n}(P(E \cap H_i))}{\sum_{i = 1}^{n}(P(H_i))}\]
	Quindi:
	\[P(E) = \frac{\sum_{i = 1}^{n}P(E | H_i)P(H_i)}{\sum_{i = 1}^{n}P(H_i)}\]
	Vale se e solo se si ha che una classe completa di ipotesi.
	
	\section{Teorema di Bayes/Laplace}
	Persa una certa ipotesi $H_i$, possiamo definire usando il teorema della probabilià composta:
	\[P(E \cap H_i) = P(E|H_i)P(H_i)\]
	\[P(H_i \cap E) = P(H_i | E)P(E)\]
	uguagliando:
	\[P(E|H_i)P(H_i) = P(H_i | E)P(E)\]
	\[P(H_i | E) = \frac{P(E | H_i)P(H_i)}{P(E)}\]
	Sapendo che $H_i \subset \Omega$, e $H_i, i \in \{1, \cdots, n\}$ è una classe di ipotesi.
	\[P(H_i | E) = \frac{P(E | H_i)P(H_i)}{\sum_{i = 1}^{n}P(E | H_i)P(H_i)}\] 
	
	Allora, 
	\[P(H_i | E) \quad \alpha \quad P(E | H_i)P(H_i)\]
	
	si ha la posterior ($P(H_i | E)$) proporzionale alla likelihood ($P(E | H_i)$) per la prior ($P(H_i)$), il risultato è una posterior probability di una specifica ipotesi.
	
	Se si hanno due ipotesi, $H_i, H_j$, allora:
	\[P(H_i | E) = \frac{P(E | H_i)P(H_i)}{\sum_{i = 1}^{n}P(E | H_i)P(H_i)}\] 
	
	\[P(H_j | E) = \frac{P(E | H_j)P(H_i)}{\sum_{i = 1}^{n}P(E | H_i)P(H_i)}\]
	si può quindi fare il rapporto:
	\[\frac{P(H_i | E)}{P(H_j | E)} = \frac{\frac{P(E | H_i)P(H_i)}{\sum_{i = 1}^{n}P(E | H_i)P(H_i)}}{\frac{P(E | H_j)P(H_i)}{\sum_{i = 1}^{n}P(E | H_i)P(H_i)}} = \frac{P(E | H_i)P(H_i)}{P(E | H_j)P(H_i)} = \frac{P(E | H_i)}{P(E | H_j)} \cdot \frac{P(H_i)}{P(H_j)}\]
	ed è chiamato rapporto delle verosimiglianze, o likelihood ration, chiamato anche Bayes factor.
	
	Preso $\Omega = H_i \cup \overline{H_i}$, con $n = 2$, in questo caso:
	\[P(H_i | E) = \frac{P(E|H_i)P(H_i)}{P(E|H_i)P(H_i) + P(E|\overline{H_i})P(\overline{H_i})} = \frac{P(H_i)}{P(H_i) + \frac{P(E | \overline{H_i})}{P(E|H_i)}P(\overline{H_i})}\]
	
	Escludere una teoria è possibile solo quando:
	\[P(H_i | E) = 0 \iff P(H_i) = 0\]
	quindi si può escludere una ipotesi solo se prima di fare la misura sapevo già che non sarebbe possibile.
	
	Il teorema di Bayes si può usare in modo iterativo, prendendo n eventi:
	\[E_1, E_2, \cdots, E_n\]
	e una certa ipotesi:
	\[H_k\]
	con una certa probabilità a priori:
	\[P(H_k)\]
	Misurando $E_1$, allora:
	\[P(H_k|E_1) \alpha P(E_1 | H_k)P(H_k)\]
	misurando ancora:
	\[P(H_k | E_2 \wedge E_1) \alpha P(E_2 | H_k) \cdot P(H_k | E_1) = P(E_2 | H_k)P(E_1 | H_k)P(H_k)\]
	e così via, in generale dopo n misure:
	\[P(H_k | E_n \wedge E_{n-1} \wedge \cdots \wedge E_1) =  P(H_k) \prod_{i = 1}^{n}P(E_1 | H_k)\]
	solo quindi indipendenti in probabilità.
	\[\prod_{i = 1}^{n}P(E_1 | H_k) = \mathcal{L}_{\text{tot}} = \prod_{i = 1}^{n} \mathcal{L}_i\]
	
	Esempio:
	Ipotizzano di aver fatto un test HIV con efficienza del $99.9\%$ ed è risultato positivo, inoltre ha un tasso di falsi positivi di $0.2\%$, quanto è la vera probabilità di essere veramente infetti?
	
	Definisco $H_i = I$, ovvero infatti, e $\overline{H_i} = S$ ovvero sani:
	\[\begin{cases}
		P(+ | I) = 0.999 \\
		P(+ | S) = 2 \cdot 10^{-3}
	\end{cases}\]
	Allora il potere predittivo positivo è:
	\[P(I | +) = \frac{P(+ | I)P(I)}{P(+ | I)P(I) + P(+ | S)P(S)} = \frac{0.999 \cdot P(I)}{0.999 P(I) \cdot 2 \cdot 10^{-3} P(S)}\]
	per svolgere il calcolo bisogna stimare la probabilità di essere infetti:
	\[\frac{0.999 \cdot P(I)}{0.999 P(I) \cdot 2 \cdot 10^{-3} P(S)} = \frac{0.999 \cdot 10^{-3}}{0.999 \cdot 10^{-3} + 2 \cdot 10^{-3} \cdot 0.999} = \frac{1}{3}\]
	
	Ora si svolge un altro test, ed è ancora positivo:
	\[P(I | + \wedge +) = \frac{P(++| I)P(I | +)}{P(++|I)P(I|+) + P(++|S)P(S|H)} = \]
	\[ = \frac{P(+_2|I)P(+_1|I)P(I)}{P(+_2|I)P(+_1|I)P(I) + P(+_2|S)P(+_1|S)P(S)} = \frac{0.999 \cdot 0.999 \cdot 10^{-3}}{0.999 \cdot 0.999 \cdot 10^{-3} + 2 \cdot 10^{-3} \cdot 2 \cdot 10^{-3} \cdot 0.999} = \]
	\[= \frac{0.999}{0.999 + 4 \cdot 10^{-3}} = 99.6\%\]
	Questo risultato sarebbe stato diverso se si fossero fatte ipotesi iniziali diverse.
	
	Esempio 2:
	Prese 5 scatole:
	\begin{enumerate}
		
		\item 5 bianche e 0 nere
		\item 4 bianche e 1 nere
		\item 3 bianche e 2 nere
		\item 2 bianche e 3 nere
		\item 1 bianche e 4 nere
		\item 0 bianche e 5 nere
	\end{enumerate}
	A priori prendere una scatola ha la stessa probabilità, allora $P(H_i) = \frac{1}{6}, \forall i \in [0, 5]$
	\[P(N | H_i) = \frac{i}{5}\]
	\[P(B | H_i) = \frac{5 - i}{5}\]
	
	Allora estraendo una pallina nera:
	\[P(H_i | N_1) = \frac{P(N_1|H_i)P(H_i)}{P(N_1)} = \frac{P(N_1|H_i)P(H_i)}{\sum_{i = 0}^{5} P(N_1 |H_i)P(H_1)} = \frac{\frac{i}{5} \cdot \frac{1}{6}}{\sum_{i = 0}^{5} \frac{i}{5} \cdot \frac{1}{6}} = \frac{i}{15}\]
	Pesco una nuova pallina, ed esce bianca:
	\[P(H_i | B_2 \wedge N_1) = \frac{P(B_2 | H_i)P(H_i|N_1)}{\sum_{i = 0}^{5} P(B_2|H_i)P(H_i|N_1)} = \frac{\frac{5 - i}{5}} \cdot \frac{i}{15}{\sum_{i = 0}^{5} \frac{5 - i}{5}} \cdot \frac{i}{15} = \frac{(5 - i)i}{20}\]
	Se fosse uscita una nuova nera:
	\[P(H_i | N_2 \wedge N_1) = \frac{P(N_2 | H_i)P(H_i|N_1)}{\sum_{i = 0}^{5} P(N_2|H_i)P(H_i|N_1)} = \frac{\frac{i}{5}\cdot \frac{i}{denominatore}}{denominatore}\] %%TO DO
	Estraendo una nuova pallina, che esce nera, dopo averne estratta una nera e una bianca:
	%%DA COMPLETARE
	Allora ora:
	\[\begin{array}{c | c | c | c | c | c | c |}
		P(H_i) & H_0 & H_1 & H_2 & H_3 & H_4 & H_5 \\
		\hline
		\text{priori} & \frac{1}{6} & \frac{1}{6} & \frac{1}{6} & \frac{1}{6} & \frac{1}{6} & \frac{1}{6} \\
		N_1 & 0 & \frac{1}{15} & \frac{1}{15} & \frac{2}{15} & \frac{4}{15} & \frac{1}{3} \\
		B_2, N_1 & 0 & \frac{1}{5} & \frac{3}{10} & \frac{3}{10} & \frac{1}{5} & 0 \\
		N_2, N_1 & 0 & \frac{1}{55} & \frac{4}{55} & \frac{9}{55} & \frac{16}{55} & \frac{25}{55} \\
	\end{array}\]
	
	Se $N_3 \wedge B_2 \wedge N_1 \Rightarrow P(B_4)$?
	\[P(B_4 | N_3 \wedge B_2 \wedge N_1) = \sum_{i = 0}^{5} P(B_4 | H_i)P(H_i | N_3 \wedge B_2 \wedge N_1) = \]
	\[ = \sum_{i = 0}^{5} \frac{5 - 1}{5}\frac{(5-i)i^2}{50} = \frac{1}{250}(5-i)^2i^2 = \frac{104}{250} \simeq 41.6\%\]
	
\end{document}
